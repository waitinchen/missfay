"""
Voice Bridge - ElevenLabs API æ¡¥æ¥å™¨ (é›†æˆ PhiBrain)
å®ç°æ–‡å­—æµåˆ° ElevenLabs é«˜è´¨é‡è¯­éŸ³çš„æ— ç¼è½¬æ¢ï¼Œå†…ç½® PhiBrain é€»è¾‘
"""

import os
import sys
import asyncio
import subprocess
import logging
import uuid
import time
import json
import re
from datetime import datetime
from typing import Optional, List, Dict, Any

from fastapi import FastAPI, HTTPException, BackgroundTasks, Security, status
from fastapi.security.api_key import APIKeyHeader
from fastapi.responses import StreamingResponse, Response, FileResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from dotenv import load_dotenv

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
_base_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(_base_dir, "static/output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# éŸ³è¨Šæ¸…ç†é‚è¼¯
async def cleanup_audio_file(file_path: str, delay: int = 600):
    """åœ¨å»¶é²æ™‚é–“å¾Œåˆªé™¤éŸ³è¨Šæ–‡ä»¶"""
    await asyncio.sleep(delay)
    if os.path.exists(file_path):
        try:
            os.remove(file_path)
            logger.info(f"ğŸ—‘ï¸ Automatically cleaned up audio file: {file_path}")
        except Exception as e:
            logger.error(f"Failed to cleanup file {file_path}: {e}")

# ============================================
# çµ‚æ¥µè·¯å¾‘ä¿®æ­£èˆ‡ä¾è³´ä¿®å¾©ï¼ˆè§£æ±ºç”Ÿç”¢ç’°å¢ƒ 500 éŒ¯èª¤ï¼‰
# ============================================
def force_recovery_deps():
    """å¼·åˆ¶è·¯å¾‘é–å®šèˆ‡ä¾è³´æ¢å¾©é‚è¼¯"""
    # 1. å„ªå…ˆæ³¨å…¥æ‰€æœ‰å¯èƒ½çš„ç”Ÿç”¢ç’°å¢ƒåŒ…è·¯å¾‘
    possible_site_packages = [
        os.path.join(os.getcwd(), "deps"),
        "/app/.local/lib/python3.11/site-packages",
        "/root/.local/lib/python3.11/site-packages",
        os.path.expanduser("~/.local/lib/python3.11/site-packages"),
    ]
    
    for path in possible_site_packages:
        if os.path.exists(path) and path not in sys.path:
            logger.info(f"Injecting path: {path}")
            sys.path.insert(0, path)

    # 2. å˜—è©¦å°å…¥ä¾è³´
    try:
        import google.generativeai
        logger.info("âœ… google-generativeai is now reachable.")
    except ImportError:
        logger.warning("âš ï¸ google-generativeai still missing. Executing Emergency OS-level Install...")
        
        # å®šç¾©æœ¬åœ°è£œä¸ç›®éŒ„
        patch_dir = os.path.join(os.getcwd(), "deps")
        os.makedirs(patch_dir, exist_ok=True)
        if patch_dir not in sys.path:
            sys.path.insert(0, patch_dir)

        try:
            # ä½¿ç”¨ --target å¼·åˆ¶å®‰è£åˆ°æˆ‘å€‘é–å®šçš„ç›®éŒ„
            install_cmd = [sys.executable, "-m", "pip", "install", "--break-system-packages", "--target", patch_dir, "google-generativeai", "grpcio"]
            logger.info(f"Running Install: {' '.join(install_cmd)}")
            subprocess.check_call(install_cmd)
            
            # å®‰è£å¾Œæ¸…é™¤å°åŒ…ç·©å­˜ä¸¦é‡æ–°å˜—è©¦
            import importlib
            importlib.invalidate_caches()
            import google.generativeai
            logger.info("âœ… Emergency OS-level Install Successful.")
        except Exception as e:
            logger.error(f"âŒ Emergency OS-level Install Failed: {e}")
            # æœ€å¾Œä¸€æ‹›ï¼šå˜—è©¦ç³»çµ±å±¤ç´šç›´æ¥å®‰è£ (ç„¡è¦– target)
            os.system(f"{sys.executable} -m pip install --break-system-packages google-generativeai grpcio elevenlabs")

    # 3. å˜—è©¦å°å…¥ ElevenLabs (å®Œæ•´æ€§æª¢æŸ¥)
    try:
        from elevenlabs.client import ElevenLabs
        logger.info("âœ… elevenlabs.client is reachable.")
    except ImportError:
        logger.warning("âš ï¸ elevenlabs missing or broken. Attempting install...")
        try:
             # å¼·åˆ¶å®‰è£ elevenlabs åŠå…¶æ ¸å¿ƒä¾è³´
            install_cmd = [sys.executable, "-m", "pip", "install", "--break-system-packages", "--target", patch_dir, "elevenlabs", "typing_extensions", "httpx"]
            subprocess.check_call(install_cmd)
            import importlib
            importlib.invalidate_caches()
            import elevenlabs
            logger.info("âœ… ElevenLabs installed successfully.")
        except Exception as e:
            logger.error(f"âŒ ElevenLabs install failed: {e}")

# åŸ·è¡Œä¿®å¾© (å¦‚æœç’°å¢ƒç¼ºå°‘ä¾è³´å‰‡è‡ªå‹•è£œå…¨)
force_recovery_deps()

# ç¡®ä¿å½“å‰ç›®å½•åœ¨è·¯å¾„ä¸­ï¼ˆå¿…é ˆåœ¨ deps ä¹‹å‰ï¼Œå¦å‰‡æœƒæ‰¾ä¸åˆ° phi_brainï¼‰
_project_root = os.path.dirname(os.path.abspath(__file__))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)
    logger.info(f"Added project root to sys.path: {_project_root}")

logger = logging.getLogger(__name__)

# ============================================
# å¤–äº¤å®˜æ¨¡çµ„ï¼šå®‰å…¨èˆ‡è³‡æºç®¡ç†é‚è¼¯
# ============================================
API_KEY_NAME = "X-API-KEY"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

async def get_api_key(api_key: str = Security(api_key_header)):
    bridge_api_key = os.getenv("BRIDGE_API_KEY")
    if not bridge_api_key:
        logger.error("BRIDGE_API_KEY is not set in environment variables!")
        raise HTTPException(status_code=500, detail="ç³»çµ±æœªé…ç½® BRIDGE_API_KEY")
        
    if api_key == bridge_api_key:
        return api_key
    raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="ç„¡æ•ˆçš„ API Keyï¼Œè²è²ä¸è·Ÿä½ èªªè©±ï¼")

# ============================================
# å¼ºåˆ¶é‡æ–°åŠ è½½ .env ç¯å¢ƒå˜é‡ï¼ˆä¿®å¤ 401 é”™è¯¯ï¼‰
# ============================================
_base_dir = os.path.dirname(os.path.abspath(__file__))
_env_path = os.path.join(_base_dir, ".env")

# ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆRailway/ç”Ÿäº§ç¯å¢ƒï¼‰
# å¦‚æœ .env æ–‡ä»¶å­˜åœ¨ï¼Œä¹Ÿå°è¯•åŠ è½½ï¼ˆæœ¬åœ°å¼€å‘ç¯å¢ƒï¼‰
if os.path.exists(_env_path):
    load_dotenv(_env_path, override=True)
    # æ‰‹åŠ¨åŠ è½½å¹¶å¤„ç†å¯èƒ½çš„ BOMï¼ˆåŒé‡ä¿é™©ï¼‰
    try:
        with open(_env_path, 'r', encoding='utf-8') as f:
            env_content = f.read().lstrip('\ufeff')
            for line in env_content.splitlines():
                if '=' in line and not line.startswith('#') and line.strip():
                    k, v = line.split('=', 1)
                    os.environ[k.strip()] = v.strip()
        logger.info("Manually parsed .env to bypass potential BOM issues.")
    except Exception as e:
        logger.warning(f"Manual .env parse failed: {e}")
else:
    # Railway/ç”Ÿäº§ç¯å¢ƒï¼šç›´æ¥ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è¯»å–
    logger.info("No .env file found, using system environment variables (Railway/production mode)")
    load_dotenv(override=False)  # ä¸è¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡

# è°ƒè¯•è¾“å‡ºï¼šç¡®è®¤ ELEVENLABS_API_KEY æ˜¯å¦æ­£ç¡®åŠ è½½
_eleven_key = os.getenv("ELEVENLABS_API_KEY")
if _eleven_key:
    _key_preview = _eleven_key[:10] + "..." + _eleven_key[-5:] if len(_eleven_key) > 15 else _eleven_key
    logger.info(f"DEBUG: ElevenLabs Key loaded: {_key_preview} (length: {len(_eleven_key)})")
else:
    logger.error("CRITICAL: ELEVENLABS_API_KEY not found in environment variables!")

# å·²è¿ç§»è‡³ Geminiï¼Œä¸å†éœ€è¦ OPENROUTER_API_KEY
if not os.getenv("GEMINI_API_KEY"):
    logger.warning("GEMINI_API_KEY not found, but continuing...")

from phi_brain import PhiBrain, PersonalityMode, ArousalLevel

# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title="Phi Voice Bridge (Integrated)",
    description="ElevenLabs + PhiBrain ç»Ÿä¸€æ¡¥æ¥å™¨",
    version="2.1.0"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ ¸å¿ƒé…ç½®
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "n41RXbR5qDhB6k5M6gyU")  # é»˜è®¤ä½¿ç”¨ç”¨æˆ·æä¾›çš„ Phi éŸ³è‰²
MODEL_ID = "eleven_multilingual_v2" # æ”¯æŒå¤šè¯­è¨€çš„ V2 æ¨¡å‹

# éªŒè¯ ELEVENLABS_API_KEY
if not ELEVENLABS_API_KEY:
    logger.error("CRITICAL: ELEVENLABS_API_KEY is missing! TTS will fail.")
    raise ValueError("ELEVENLABS_API_KEY is required. Please check your .env file.")
else:
    logger.info(f"ElevenLabs API Key loaded successfully (length: {len(ELEVENLABS_API_KEY)})")

# åˆå§‹åŒ–å¤§è„‘ (PhiBrain)
brain = None
brain_init_error = None  # å­˜å‚¨åˆå§‹åŒ–é”™è¯¯ä¿¡æ¯ï¼Œç”¨äºè¯Šæ–­
try:
    # å·²è¿ç§»è‡³ Geminiï¼Œæ£€æŸ¥ GEMINI_API_KEY
    gemini_key = os.getenv("GEMINI_API_KEY")
    
    # è¯¦ç»†æ—¥å¿—ï¼šåˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„ç¯å¢ƒå˜é‡
    logger.info("=== Environment Variables Check ===")
    logger.info(f"GEMINI_API_KEY exists: {gemini_key is not None}")
    if gemini_key:
        logger.info(f"GEMINI_API_KEY length: {len(gemini_key)}")
        logger.info(f"GEMINI_API_KEY starts with: {gemini_key[:5] if len(gemini_key) >= 5 else 'INVALID'}")
    else:
        logger.error("CRITICAL: GEMINI_API_KEY is None or empty!")
        # åˆ—å‡ºæ‰€æœ‰åŒ…å« GEMINI çš„ç¯å¢ƒå˜é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰
        gemini_vars = {k: v for k, v in os.environ.items() if 'GEMINI' in k.upper()}
        logger.info(f"All GEMINI-related env vars: {list(gemini_vars.keys())}")
    
    if not gemini_key:
        error_msg = "GEMINI_API_KEY is required. Please check your Railway environment variables."
        logger.error(f"CRITICAL: {error_msg}")
        brain_init_error = error_msg
        raise ValueError(error_msg)
    
    logger.info(f"GEMINI_API_KEY found (length: {len(gemini_key)})")
    brain = PhiBrain(
        api_type="gemini",  # è¿ç§»è‡³ Gemini 2.0 Flash
        personality=PersonalityMode.MIXED
    )
    logger.info("âœ… PhiBrain (LLM) initialized successfully.")
except Exception as e:
    import traceback
    error_trace = traceback.format_exc()
    logger.error(f"âŒ Failed to initialize PhiBrain: {str(e)}")
    logger.error(error_trace)
    brain = None
    brain_init_error = f"{str(e)}\n\nTraceback:\n{error_trace}"
    logger.error("âš ï¸  LLM service will not be available. Please check Railway logs for details.")

class TTSRequest(BaseModel):
    text: str = Field(..., description="è¦åˆæˆçš„æ–‡æœ¬")
    text_language: str = Field("zh", description="æ–‡æœ¬è¯­è¨€")
    arousal_level: Optional[int] = Field(0, description="å…´å¥‹åº¦ç­‰çº§", ge=0, le=4)
    speed: Optional[float] = Field(1.0, description="è¯­é€Ÿ")

class PhiVoiceRequest(BaseModel):
    user_input: str = Field(..., description="ç”¨æˆ¶æ¬²å‚³é”çµ¦å¿ƒè²çš„æ–‡å­—")
    session_id: Optional[str] = Field("default", description="ç”¨æ–¼ç¶­æŒä¸Šä¸‹æ–‡é€£è²«æ€§çš„å”¯ä¸€è­˜åˆ¥ç¢¼")

class ChatRequest(BaseModel):
    message: str = Field(..., description="è¦å‚³é€çµ¦è²è²çš„è¨Šæ¯")
    user_id: Optional[str] = Field("MISSAV_USER", description="å¤–éƒ¨ç”¨æˆ¶è­˜åˆ¥ç¢¼")

@app.get("/api", response_class=HTMLResponse)
async def get_api_docs():
    """è¿”å›å°ˆæ¥­çš„ API å°æ¥æ–‡ä»¶é é¢"""
    docs_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "static/api_docs.html")
    if os.path.exists(docs_path):
        with open(docs_path, "r", encoding="utf-8") as f:
            return f.read()
    return HTMLResponse(content="<h1>API Docs Not Found</h1>", status_code=404)

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - åŒ…å« LLM å’Œ TTS çŠ¶æ€"""
    brain_status = "ready" if brain is not None else "not_ready"
    tts_error = None
    
    # æ£€æŸ¥ ElevenLabs API Key
    eleven_status = "ready" if ELEVENLABS_API_KEY else "not_ready"
    
    # ç®€å•çš„å®¢æˆ·ç«¯åˆå§‹åŒ–æ£€æŸ¥
    if ELEVENLABS_API_KEY:
        try:
            from elevenlabs.client import ElevenLabs
            # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆä¸è°ƒç”¨ APIï¼‰
            test_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
            eleven_status = "ready"
        except ImportError as e:
            eleven_status = "import_error"
            tts_error = str(e)
            logger.error(f"TTS Import Failed: {e}")
        except Exception as e:
            eleven_status = "error"
            tts_error = str(e)
            logger.error(f"TTS Health Check Failed: {e}")
    
    # æ£€æŸ¥ GEMINI_API_KEY è¯Šæ–­ä¿¡æ¯
    gemini_key = os.getenv("GEMINI_API_KEY")
    gemini_key_exists = gemini_key is not None and len(gemini_key) > 0
    
    # æ„å»ºè¯Šæ–­ä¿¡æ¯
    diagnostics = {}
    if not brain:
        diagnostics["gemini_key_exists"] = gemini_key_exists
        diagnostics["gemini_key_length"] = len(gemini_key) if gemini_key else 0
        if brain_init_error:
            # åªè¿”å›é”™è¯¯çš„å‰200ä¸ªå­—ç¬¦ï¼Œé¿å…å“åº”è¿‡å¤§
            diagnostics["init_error"] = brain_init_error[:200] if len(brain_init_error) > 200 else brain_init_error
    
    return {
        "status": "ok",
        "brain_ready": brain is not None,
        "brain_status": brain_status,
        "tts_status": eleven_status,
        "engine": "elevenlabs",
        "timestamp": datetime.now().isoformat(),
        "diagnostics": diagnostics if diagnostics else None,
        "tts_error_detail": str(tts_error) if tts_error else None 
    }

@app.get("/verify-keys")
async def verify_keys():
    """
    éªŒè¯ Railway ç¯å¢ƒå˜é‡çš„å¥åº·çŠ¶å†µ
    æ£€æŸ¥æ‰€æœ‰ API Key å’Œé…ç½®æ˜¯å¦æœ‰æ•ˆ
    """
    verification_results = {
        "GEMINI_API_KEY": {
            "exists": False,
            "valid": False,
            "length": 0,
            "error": None
        },
        "CARTESIA_API_KEY": {
            "exists": False,
            "valid": False,
            "length": 0,
            "error": "Deprecated"
        },
        "ELEVENLABS_API_KEY": {
            "exists": False,
            "valid": False,
            "length": 0,
            "error": None
        },
        "ELEVENLABS_VOICE_ID": {
            "exists": False,
            "valid": False,
            "value": None,
            "error": None
        },
        "GEMINI_MODEL": {
            "exists": False,
            "valid": False,
            "value": None,
            "error": None
        },
        "BRIDGE_API_KEY": {
            "exists": False,
            "valid": False,
            "length": 0,
            "error": None
        }
    }
    
    # 1. æ£€æŸ¥ GEMINI_API_KEY
    gemini_key = os.getenv("GEMINI_API_KEY")
    if gemini_key:
        verification_results["GEMINI_API_KEY"]["exists"] = True
        verification_results["GEMINI_API_KEY"]["length"] = len(gemini_key)
        try:
            import google.generativeai as genai
            genai.configure(api_key=gemini_key)
            # å°è¯•åˆ—å‡ºæ¨¡å‹ï¼ˆè½»é‡çº§éªŒè¯ï¼‰
            models = genai.list_models()
            verification_results["GEMINI_API_KEY"]["valid"] = True
        except Exception as e:
            verification_results["GEMINI_API_KEY"]["valid"] = False
            verification_results["GEMINI_API_KEY"]["error"] = str(e)
    else:
        verification_results["GEMINI_API_KEY"]["error"] = "æœªè®¾ç½®"
    
    # 3. æ£€æŸ¥ ELEVENLABS_API_KEY (åŸ Cartesia é€»è¾‘æ›¿æ¢)
    if ELEVENLABS_API_KEY:
        verification_results["ELEVENLABS_API_KEY"]["exists"] = True
        verification_results["ELEVENLABS_API_KEY"]["length"] = len(ELEVENLABS_API_KEY)
        verification_results["ELEVENLABS_API_KEY"]["valid"] = True # assume valid if exists for now
    else:
        verification_results["ELEVENLABS_API_KEY"]["error"] = "æœªè®¾ç½®"
    
    # 4. æ£€æŸ¥ ELEVENLABS_VOICE_ID
    voice_id = os.getenv("ELEVENLABS_VOICE_ID", VOICE_ID)
    if voice_id:
        verification_results["ELEVENLABS_VOICE_ID"]["exists"] = True
        verification_results["ELEVENLABS_VOICE_ID"]["value"] = voice_id
        verification_results["ELEVENLABS_VOICE_ID"]["valid"] = True
    else:
        verification_results["ELEVENLABS_VOICE_ID"]["error"] = "æœªè®¾ç½®"
    
    # 4. æ£€æŸ¥ GEMINI_MODEL
    gemini_model = os.getenv("GEMINI_MODEL", "gemini-2.0-flash-exp")
    if gemini_model:
        verification_results["GEMINI_MODEL"]["exists"] = True
        verification_results["GEMINI_MODEL"]["value"] = gemini_model
        if verification_results["GEMINI_API_KEY"]["valid"]:
            try:
                import google.generativeai as genai
                models = genai.list_models()
                model_names = [m.name for m in models]
                target_model = f"models/{gemini_model}"
                if target_model in model_names or any(gemini_model in name for name in model_names):
                    verification_results["GEMINI_MODEL"]["valid"] = True
                else:
                    verification_results["GEMINI_MODEL"]["valid"] = False
                    verification_results["GEMINI_MODEL"]["error"] = "æœªæ‰¾åˆ°æ¨¡å‹"
            except:
                verification_results["GEMINI_MODEL"]["valid"] = True
        else:
            verification_results["GEMINI_MODEL"]["valid"] = False
            verification_results["GEMINI_MODEL"]["error"] = "GEMINI_API_KEY æ— æ•ˆï¼Œæ— æ³•éªŒè¯æ¨¡å‹"
    else:
        verification_results["GEMINI_MODEL"]["error"] = "æœªè®¾ç½®"
    
    # 5. æ£€æŸ¥ BRIDGE_API_KEY
    bridge_api_key = os.getenv("BRIDGE_API_KEY")
    if bridge_api_key:
        verification_results["BRIDGE_API_KEY"]["exists"] = True
        verification_results["BRIDGE_API_KEY"]["length"] = len(bridge_api_key)
        if len(bridge_api_key) >= 8:
            verification_results["BRIDGE_API_KEY"]["valid"] = True
        else:
            verification_results["BRIDGE_API_KEY"]["valid"] = False
            verification_results["BRIDGE_API_KEY"]["error"] = "é•·åº¦ä¸è¶³"
    else:
        verification_results["BRIDGE_API_KEY"]["error"] = "æœªè¨­ç½®"
    
    # è®¡ç®—æ€»ä½“å¥åº·çŠ¶æ€
    all_valid = all(
        result.get("exists", False) and result.get("valid", False)
        for result in verification_results.values()
    )
    
    return {
        "status": "healthy" if all_valid else "unhealthy",
        "timestamp": datetime.now().isoformat(),
        "keys": verification_results,
        "summary": {
            "total": len(verification_results),
            "valid": sum(1 for r in verification_results.values() if r.get("exists", False) and r.get("valid", False)),
            "invalid": sum(1 for r in verification_results.values() if not r.get("exists", False) or not r.get("valid", False))
        }
    }

def _clean_text(text: str) -> str:
    """æ¸…ç†ç”¨äº UI æ˜¾ç¤ºçš„æ–‡æœ¬ (å¾¹åº•éæ¿¾æ‰€æœ‰èªéŸ³æ§åˆ¶æ¨™ç±¤èˆ‡è‹±èªå­—æ¯)"""
    # 1. ç§»é™¤æ‰€æœ‰ [...] å½¢å¼çš„æ¨™ç±¤ï¼ˆState, èªéŸ³å‹•ä½œç­‰ï¼‰
    text = re.sub(r'\[.*?\]', '', text)
    
    # 2. ç§»é™¤æ‰€æœ‰ <...> å½¢å¼çš„æ¨™ç±¤ (Emotion ç­‰)
    text = re.sub(r'<.*?>', '', text)
    
    # 3. ç§»é™¤æ‰€æœ‰ SoVITS æ®˜ç•™æ¨™ç±¤ (å¦‚ [speed=...])
    text = re.sub(r'\[\w+=[\w.]+\]', '', text)
    
    # 4. ç§»é™¤ *ç¬‘è²* ç­‰æè¿°æ€§æ–‡æœ¬
    text = re.sub(r'\*[^\*]+\*', '', text)
    
    # 5. å¼·åˆ¶æ·¨åŒ–ï¼šç§»é™¤æ‰€æœ‰è‹±æ–‡å­—æ¯ (a-zA-Z)
    # é€™æ˜¯ç‚ºäº†é˜²æ­¢ LLM æ´©æ¼ Inserted emote, itched to be ç­‰æŠ€è¡“æè¿°
    text = re.sub(r'[a-zA-Z]+', '', text)
    
    # 6. ç§»é™¤æ‰€æœ‰è¡¨æƒ…ç¬¦è™Ÿ (Emoji)
    text = re.sub(r'[^\u0000-\uFFFF]', '', text)
    
    return text.strip()

def _extract_emotion_from_brackets(text: str) -> dict:
    """
    ä»æ‹¬å·å†…å®¹ä¸­æå–æƒ…ç»ªä¿¡æ¯ï¼Œè½¬åŒ–ä¸º Cartesia æƒ…ç»ªå‚æ•°
    
    ä¾‹å¦‚ï¼š(å’¬ç€ä¸‹å”‡ï¼Œå£°éŸ³å¨‡åªšåœ°é—®) -> {"positivity": "high", "curiosity": "high"}
    """
    emotion_map = {
        # å…³é”®è¯ -> (positivity, curiosity, stability)
        "å¨‡åªš": ("high", "high", "medium"),
        "è¯±æƒ‘": ("high", "high", "medium"),
        "æŒ‘é€—": ("high", "high", "low"),
        "å®³ç¾": ("medium", "medium", "low"),
        "è„¸çº¢": ("medium", "medium", "low"),
        "ç´§å¼ ": ("medium", "medium", "low"),
        "å…´å¥‹": ("high", "high", "low"),
        "æ¿€åŠ¨": ("high", "high", "low"),
        "æ¸´æœ›": ("high", "high", "low"),
        "å–˜æ¯": ("high", "medium", "low"),
        "å¨‡å—”": ("high", "medium", "low"),
        "å‘»åŸ": ("high", "low", "low"),
        "å’¬ç€": ("high", "medium", "low"),
        "èˆ”": ("high", "medium", "low"),
        "æ‰": ("high", "medium", "low"),
        "å®": ("high", "medium", "low"),
    }
    
    # æå–æ‰€æœ‰æ‹¬å·å†…å®¹
    bracket_pattern = r'\(([^)]+)\)|ï¼ˆ([^ï¼‰]+)ï¼‰'
    matches = re.findall(bracket_pattern, text)
    
    emotion_params = {}
    for match in matches:
        bracket_content = match[0] or match[1]  # å¤„ç†ä¸­è‹±æ–‡æ‹¬å·
        for keyword, (pos, cur, sta) in emotion_map.items():
            if keyword in bracket_content:
                emotion_params["positivity"] = pos
                emotion_params["curiosity"] = cur
                emotion_params["stability"] = sta
                logger.info(f"Extracted emotion from bracket '{bracket_content}': {emotion_params}")
                break
    
    return emotion_params

def _clean_for_speech(text: str) -> tuple[str, dict]:
    """
    é‡å° TTS å¼•æ“çš„æ·±åº¦æ¸…ç†ï¼ˆéˆé­‚æ·¨åŒ–ç‰ˆï¼‰
    è¿”å›: (æ¸…ç†åçš„æ–‡æœ¬, ä»æ‹¬å·ä¸­æå–çš„æƒ…ç»ªå‚æ•°å­—å…¸)
    """
    # 0. å…ˆæå–æ‹¬å·ä¸­çš„æƒ…ç»ªä¿¡æ¯ï¼ˆåœ¨ç§»é™¤æ‹¬å·å‰ï¼‰
    emotion_from_brackets = _extract_emotion_from_brackets(text)
    
    # 1. å¾¹åº•ç§»é™¤ [STATE:n]
    text = re.sub(r'\[STATE:\d\]', '', text)
    
    # 2. ç§»é™¤æ‰€æœ‰ <...> å½¢å¼çš„æ¨™ç±¤ï¼Œé™¤äº† <emotion /> (æˆ‘å€‘å¾Œé¢æœƒè™•ç†)
    # ä½†ç‚ºäº†é˜²æ­¢æ´©æ¼ï¼Œæˆ‘å€‘ä¹¾è„†å…ˆç§»é™¤æ‰€æœ‰å°–æ‹¬è™Ÿå…§å®¹ï¼Œä¿ç•™å°è©±
    # æ³¨æ„ï¼š<emotion> æ¨™ç±¤æˆ‘å€‘æœƒåœ¨ /chat é‚è¼¯ä¸­å–®ç¨æå–ï¼Œé€™è£¡ä¸»è¦æ˜¯æ¸…ç†å‰©é¤˜é›œè¨Š
    
    # 3. ç§»é™¤æ‰€æœ‰èªéŸ³æ¨™ç±¤ï¼ˆElevenLabs ä¸æ”¯æŒ Cartesia æ¨™ç±¤ï¼Œæœƒç›´æ¥è®€å‡ºè‹±æ–‡å–®è©ï¼‰
    # ç™½åå–®æ¨™ç±¤åˆ—è¡¨ï¼ˆåƒ…ä¾›åƒè€ƒï¼Œå¯¦éš›æœƒè¢«ç§»é™¤ï¼‰
    whitelist_tags = [
        "laughter", "sigh", "chuckle", "gasp", "uh-huh", "hmm",
        "wink", "giggle", "moan", "squeal"
    ]
    
    # ç›´æ¥ç§»é™¤æ‰€æœ‰ Cartesia èªéŸ³æ¨™ç±¤ï¼ˆElevenLabs ä¸æ”¯æŒï¼‰
    for tag in whitelist_tags:
        text = re.sub(rf'\[{re.escape(tag)}\]', ' ', text, flags=re.IGNORECASE)

    # 4. ç§»é™¤æ‰€æœ‰æ‹¬è™Ÿå…§å®¹ (åŒ…å«å…§éƒ¨å¯èƒ½çš„äº‚ç¢¼) - ä¸å†ç›´æ¥è®€å‡ºä¾†ï¼Œè€Œæ˜¯è½‰åŒ–ç‚ºæƒ…ç·’åƒæ•¸
    # ä½¿ç”¨å¾ªç’°è™•ç†åµŒå¥—æ‹¬è™Ÿï¼Œç¢ºä¿å¾¹åº•æ¸…é™¤
    prev_text = ""
    while prev_text != text:
        prev_text = text
        text = re.sub(r'\(.*?\)|ï¼ˆ.*?ï¼‰|\[.*?\]|ã€.*?ã€‘|\{.*?\}', ' ', text)
    
    # 5. å¼·åˆ¶è‹±èªæ·¨åŒ– (Fail-safe)ï¼šç§»é™¤æ‰€æœ‰å‰©é¤˜çš„è‹±æ–‡å­—æ¯
    # ElevenLabs ä¸æ”¯æŒè‹±æ–‡æ¨™ç±¤ï¼Œå¿…é ˆå®Œå…¨ç§»é™¤
    text = re.sub(r'[a-zA-Z]+', '', text)
    
    # 6. æ¨™é»ç¬¦è™Ÿæ­£è¦åŒ–
    text = re.sub(r'\.{3,}', '...', text)
    text = re.sub(r'(!|\?|ã€‚|ï¼|ï¼Ÿ)\1+', r'\1', text)
    
    # 7. æœ€çµ‚æ¸…ç†ï¼šç§»é™¤æ‰€æœ‰å°–æ‹¬è™Ÿæ®˜ç•™ã€è¡¨æƒ…ç¬¦è™Ÿ (Emoji) èˆ‡å¤šé¤˜ç©ºæ ¼
    text = re.sub(r'<[^>]*>', '', text)
    text = re.sub(r'[^\u0000-\uFFFF]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return (text if text else "ã€‚", emotion_from_brackets)

def _clause_buffer(text: str) -> str:
    """
    å­å¥ç¼“å†²æœºåˆ¶ (Clause Buffering)
    ç¡®ä¿æ–‡æœ¬æ˜¯å®Œæ•´çš„å¥å­ï¼Œé¿å…ç ´ç¢çš„å­—èŠ‚æµå¯¼è‡´å¾ªç¯å´©æºƒ
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°ä¼šä¸´æ—¶ä¿ç•™æ ‡ç­¾ä»¥ä¾¿å¥å­åˆ†å‰²ï¼Œä½†æ ‡ç­¾ä¼šåœ¨åç»­çš„ _clean_for_speech 
    å‡½æ•°ä¸­è¢«ç§»é™¤ï¼ˆå› ä¸º ElevenLabs ä¸æ”¯æŒè¿™äº›æ ‡ç­¾ï¼‰ã€‚
    """
    # re æ¨¡å—å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œæ— éœ€é‡å¤å¯¼å…¥
    
    # Cartesia æ”¯æŒçš„æ ‡ç­¾ç™½åå•ï¼ˆè¿™äº›æ ‡ç­¾ä¸åº”è¯¥è¢«ç§»é™¤ï¼‰
    cartesia_tags_whitelist = [
        r'\[laughter\]', r'\[sigh\]', r'\[chuckle\]', r'\[gasp\]',
        r'\[uh-huh\]', r'\[hmm\]', r'\[wink\]', r'\[giggle\]',
        r'\[moan\]', r'\[squeal\]'
    ]
    
    # ä¸´æ—¶ä¿æŠ¤ Cartesia æ ‡ç­¾ï¼šç”¨å ä½ç¬¦æ›¿æ¢
    tag_map = {}
    protected_text = text
    for idx, pattern in enumerate(cartesia_tags_whitelist):
        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ ‡ç­¾
        matches = list(re.finditer(pattern, protected_text, re.IGNORECASE))
        # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
        for match in reversed(matches):
            placeholder = f"__CARTESIA_TAG_{idx}_{match.start()}__"
            tag_map[placeholder] = match.group(0)  # å­˜å‚¨åŸå§‹æ ‡ç­¾
            protected_text = protected_text[:match.start()] + placeholder + protected_text[match.end():]
    
    # ç§»é™¤å…¶ä»–æ ‡ç­¾ï¼ˆSTATE æ ‡ç­¾ã€SoVITS æ ‡ç­¾ç­‰ï¼‰ï¼Œä½†ä¿ç•™ Cartesia æ ‡ç­¾
    # ç§»é™¤ STATE æ ‡ç­¾å’Œ SoVITS æ ‡ç­¾
    clean_text = re.sub(r'\[STATE\s*:\s*\d+\]', '', protected_text, flags=re.IGNORECASE)
    clean_text = re.sub(r'\[speed=[\w.]+\]', '', clean_text)
    clean_text = re.sub(r'\[pitch=[\w.]+\]', '', clean_text)
    clean_text = re.sub(r'\[emotion=[\w.]+\]', '', clean_text)
    clean_text = re.sub(r'<emotion[^>]*>', '', clean_text)
    clean_text = re.sub(r'<[^>]+>', '', clean_text)  # ç§»é™¤å…¶ä»– XML æ ‡ç­¾
    
    # æŒ‰å¥å­åˆ†å‰²ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
    sentence_endings = r'[ã€‚ï¼ï¼Ÿ.!?]'
    sentences = re.split(f'({sentence_endings})', clean_text)
    
    # é‡æ–°ç»„åˆå¥å­ï¼ˆä¿ç•™åˆ†éš”ç¬¦ï¼‰
    complete_sentences = []
    for i in range(0, len(sentences) - 1, 2):
        if i + 1 < len(sentences):
            sentence = sentences[i] + sentences[i + 1]
            if sentence.strip():
                complete_sentences.append(sentence.strip())
    
    # æ¢å¤ Cartesia æ ‡ç­¾çš„è¾…åŠ©å‡½æ•°
    def restore_tags(text_with_placeholders):
        result = text_with_placeholders
        for placeholder, original_tag in tag_map.items():
            result = result.replace(placeholder, original_tag)
        return result
    
    # å¦‚æœæ²¡æœ‰å¥å­åˆ†éš”ç¬¦ï¼Œæ¢å¤æ ‡ç­¾åè¿”å›åŸå§‹æ–‡æœ¬
    if not complete_sentences:
        return restore_tags(protected_text).strip()
    
    # ç¡®ä¿æœ€åä¸€ä¸ªå¥å­å®Œæ•´ï¼ˆå¦‚æœä¸æ˜¯ä»¥å¥å­ç»“æŸç¬¦ç»“å°¾ï¼Œä¿ç•™åŸæ–‡æœ¬ï¼‰
    last_sentence = sentences[-1].strip() if sentences else ""
    if last_sentence and not re.search(sentence_endings, last_sentence):
        # å¦‚æœæœ€åä¸€æ®µä¸æ˜¯å®Œæ•´å¥å­ï¼Œæ¢å¤æ ‡ç­¾åè¿”å›åŸæ–‡æœ¬
        return restore_tags(protected_text).strip()
    
    # æ–‡æœ¬å®Œæ•´ï¼Œæ¢å¤æ ‡ç­¾å¹¶è¿”å›
    return restore_tags(protected_text).strip()

def _pre_process_tags(text: str) -> str:
    """æ¨™ç±¤é è™•ç†ï¼šæ ¹æ“šç”Ÿç†é‚è¼¯è‡ªå‹•ä¿®æ­£éŒ¯èª¤æè¿°"""
    # 1. ç‰©ç†å¸¸è­˜æ ¡æ­£ï¼šå°è±†è±†ä¸å¯è¢«ã€Œæ’/å¹¹/æ…ã€
    # åŒ¹é…å°ã€Œå°è±†è±†/é™°æ ¸ã€é€²è¡Œæ’å…¥é¡å‹•ä½œçš„æè¿°
    impossibilities = ["å¹¹å°è±†è±†", "æ’å°è±†è±†", "æ…å°è±†è±†", "å¹¹é™°æ ¸", "æ’é™°æ ¸", "æ…é™°æ ¸"]
    for err in impossibilities:
        if err in text:
            fix = err.replace("å¹¹", "ç˜‹ç‹‚èˆ”å¼„").replace("æ’", "é«˜é€Ÿæ’¥å¼„").replace("æ…", "ç”¨åŠ›å®å¸")
            text = text.replace(err, fix)
            logger.info(f"Physiological Correction Applied: {err} -> {fix}")
    
    # 2. è‡ªå‹•è£œå…¨æƒ…ç·’æ¨™ç±¤ - ElevenLabs æ›´ä¾è³´èªç¾©ï¼Œä½†æˆ‘å€‘ä»å¯ä»¥è£œå…¨ä»¥ä¾›åƒè€ƒ
    # (å¦‚æœæœªä¾†éœ€è¦ï¼Œå¯ä»¥åœ¨é€™è£¡åŠ å…¥æç¤ºè©ä¿®æ”¹)
        
    return text

@app.post("/api/v1/phi_voice")
async def phi_voice_proxy(request: PhiVoiceRequest):
    """
    æ¥µç°¡å°æ¥æ¥å£ (Proxy Pattern)
    éš±è—æ‰€æœ‰ API Key èˆ‡å…§éƒ¨åƒæ•¸ï¼Œç›´æ¥ä¸²æµå›å‚³éŸ³è¨Šã€‚
    """
    if not brain:
        raise HTTPException(status_code=500, detail="PhiBrain is not initialized.")

    try:
        # 1. ç²å– LLM å›è¦† (ä½¿ç”¨ session_id æ”¯æŒå¤šæœƒè©±)
        # generate_response(user_message, context, include_tags, session_id)
        ai_response_text, metadata = brain.generate_response(
            request.user_input, 
            session_id=request.session_id
        )

        # 2. å­å¥ç¼“å†²éªŒè¯ï¼ˆç¡®ä¿æ–‡æœ¬å®Œæ•´ï¼‰
        buffered_text = _clause_buffer(ai_response_text)
        
        # 3. æ¨™ç±¤é è™•ç† (ç‰©ç†æ ¡æ­£èˆ‡æ¨™ç±¤è‡ªå‹•æ³¨å…¥)
        processed_text = _pre_process_tags(buffered_text)

        # 4. æå–æƒ…ç·’æ¨™ç±¤
        cartesia_emotion = None
        emotion_match = re.search(r'<emotion\s+value=["\']([^"\']+)["\']\s*/>', processed_text)
        if emotion_match:
            cartesia_emotion = emotion_match.group(1)

        # 5. èªéŸ³åŒ–æ¸…ç†ï¼ˆè¿”å›æ–‡æœ¬å’Œä»æ‹¬å·æå–çš„æƒ…ç»ªå‚æ•°ï¼‰
        speech_text, emotion_from_brackets = _clean_for_speech(processed_text)

        # 6. è·èˆˆå¥®åº¦ä¸¦æ˜ å°„åˆ° ElevenLabs åƒæ•¸
        # ElevenLabs ä¸æ”¯æŒ [STATE], [speed] ç­‰æ¨™ç±¤ï¼Œæˆ‘å€‘é€šé stability/similarity_boost æ§åˆ¶
        
        # åƒæ•¸æ˜ å°„é‚è¼¯ï¼š
        # - Stability: è¶Šä½è¶Šä¸ç©©å®šï¼Œæƒ…ç·’è¶Šæ¿€å‹• (Range 0.0 - 1.0)
        # - Similarity: è¶Šé«˜è¶ŠåƒåŸè²ï¼Œè¶Šä½å¯èƒ½æœ‰æ›´å¤šè®ŠåŒ– (Range 0.0 - 1.0)
        # - Style: èª‡å¼µç¨‹åº¦ (Range 0.0 - 1.0)
        
        eleven_params = {
            ArousalLevel.CALM: {"stability": 0.8, "similarity_boost": 0.75, "style": 0.0},
            ArousalLevel.NORMAL: {"stability": 0.5, "similarity_boost": 0.75, "style": 0.0},
            ArousalLevel.EXCITED: {"stability": 0.4, "similarity_boost": 0.6, "style": 0.3},
            ArousalLevel.INTENSE: {"stability": 0.3, "similarity_boost": 0.5, "style": 0.6},
            ArousalLevel.PEAK: {"stability": 0.25, "similarity_boost": 0.4, "style": 0.8} # æ¥µåº¦æ¿€å‹•
        }
        
        current_config = eleven_params.get(brain.arousal_level, eleven_params[ArousalLevel.NORMAL])
        
        # å¦‚æœæ‹¬è™Ÿå…§æœ‰æ˜ç¢ºæƒ…ç·’ï¼Œé€²ä¸€æ­¥å¾®èª¿ (ç°¡å–®é‚è¼¯ï¼šå¦‚æœæœ‰æƒ…ç·’æå–ï¼Œå¢åŠ  styleï¼Œé™ä½ stability)
        if emotion_from_brackets:
            current_config["stability"] = max(0.1, current_config["stability"] - 0.1)
            current_config["style"] = min(1.0, current_config["style"] + 0.2)
            logger.info(f"Adjusted ElevenLabs params due to emotional brackets: {current_config}")

        # 7. èª¿ç”¨ ElevenLabs API
        from elevenlabs.client import ElevenLabs
        
        if not ELEVENLABS_API_KEY:
             raise HTTPException(status_code=500, detail="ELEVENLABS_API_KEY is missing!")
             
        client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        
        logger.info(f"Generating ElevenLabs audio. Text: {speech_text[:20]}... | Params: {current_config}")
        
        audio_stream = client.text_to_speech.convert(
            voice_id=VOICE_ID,
            optimize_streaming_latency="2", # 1-4, 4 is max latency but best quality. 2 is balanced.
            output_format="mp3_44100_128",
            text=speech_text,
            model_id=MODEL_ID,
            voice_settings=current_config
        )

        return StreamingResponse(audio_stream, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"API Proxy Error: {str(e)}", exc_info=True)
        return Response(content=json.dumps({"error": str(e)}), status_code=500, media_type="application/json")

@app.post("/chat")
async def unified_chat(request: TTSRequest):
    if not brain:
        # æä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
        gemini_key = os.getenv("GEMINI_API_KEY")
        error_detail = "å¤§è„‘ (LLM) æœªå°±ç»ªï¼Œè¯·æ£€æŸ¥ API Key"
        
        if not gemini_key:
            error_detail += "\n\nè¯Šæ–­ä¿¡æ¯:\n- GEMINI_API_KEY æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ°\n- è¯·æ£€æŸ¥ Railway ç¯å¢ƒå˜é‡è®¾ç½®\n- ç¡®ä¿å˜é‡åæ­£ç¡®: GEMINI_API_KEY"
        elif brain_init_error:
            error_detail += f"\n\nåˆå§‹åŒ–é”™è¯¯:\n{brain_init_error[:500]}"  # é™åˆ¶é•¿åº¦é¿å…è¿‡é•¿
        else:
            error_detail += "\n\nè¯Šæ–­ä¿¡æ¯:\n- GEMINI_API_KEY å­˜åœ¨ä½†åˆå§‹åŒ–å¤±è´¥\n- è¯·æ£€æŸ¥ Railway æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯"
        
        logger.error(f"Chat request failed: {error_detail}")
        raise HTTPException(status_code=500, detail=error_detail)

    try:
        # 1. å¤§è„‘æ€è€ƒ
        # ç§»é™¤å¼ºåˆ¶è®¾ç½®ï¼Œè®©å¤§è„‘è‡ªä¸»å†³å®šæˆ–ä¿ç•™ä¸Šæ¬¡çŠ¶æ€
        # brain.arousal_level = ArousalLevel(request.arousal_level)
        
        # generate_response è¿”å› (reply_text, metadata)
        try:
            ai_response_text, metadata = brain.generate_response(request.text)
        except ValueError as brain_error:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é”™è¯¯
            error_str = str(brain_error)
            if "429" in error_str or "è¯·æ±‚é¢‘ç‡è¿‡é«˜" in error_str or "è²è²ç´¯äº†" in error_str:
                # 429 é”™è¯¯ï¼šä¸ç”ŸæˆéŸ³é¢‘ï¼Œç›´æ¥è¿”å›é”™è¯¯æ¶ˆæ¯
                raise HTTPException(
                    status_code=429,
                    detail="ä¸»äºº~è²è²ç´¯äº†ï¼Œè¯·ç­‰ 60 ç§’å†æ‰¾æˆ‘~ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰"
                )
            else:
                # å…¶ä»–é”™è¯¯ï¼Œç»§ç»­æŠ›å‡º
                raise
        
        # ç¡®ä¿ ai_response_text æ˜¯å­—ç¬¦ä¸²
        if not isinstance(ai_response_text, str):
            ai_response_text = str(ai_response_text)
            
        # --- è‡ªä¸»æƒ…æ„Ÿè§£æ ---
        state_match = re.search(r'\[STATE\s*:\s*(\d+)\]', ai_response_text, re.IGNORECASE)
        if state_match:
            new_level_val = int(state_match.group(1))
            # é™åˆ¶åœ¨ 0-4 ä¹‹é—´
            new_level_val = max(0, min(4, new_level_val))
            brain.arousal_level = ArousalLevel(new_level_val)
            # ä»æ–‡æœ¬ä¸­ç§»é™¤ STATE æ ‡ç­¾ (ä¸åˆ†å¤§å°å¯«èˆ‡ç©ºæ ¼)
            ai_response_text = re.sub(r'\[STATE\s*:\s*\d+\]', '', ai_response_text, flags=re.IGNORECASE).strip()
            logger.info(f"Autonomous State Switch: {brain.arousal_level.name}")
        # ------------------
            
        # 2. èªéŸ³åŒ–è™•ç†
        display_text = _clean_text(ai_response_text)
        
        # --- æƒ…æ„Ÿæ¨™ç±¤æå‰æå– ---
        # å¿…é ˆåœ¨ clean_for_speech ä¹‹å‰æå–ï¼Œå› ç‚ºå¾Œè€…æœƒæ·¨åŒ–æ‰ <>
        cartesia_emotion = None
        emotion_match = re.search(r'<emotion\s+value=["\']([^"\']+)["\']\s*/>', ai_response_text)
        if emotion_match:
            cartesia_emotion = emotion_match.group(1)
            logger.info(f"Detected Emotion for API: {cartesia_emotion}")
        
        # åŸ·è¡Œå­å¥ç¼“å†²éªŒè¯
        buffered_text = _clause_buffer(ai_response_text)
        
        # åŸ·è¡Œæ·±åº¦æ¸…ç†ï¼ˆè¿”å›æ–‡æœ¬å’Œä»æ‹¬å·æå–çš„æƒ…ç»ªå‚æ•°ï¼‰
        speech_text, emotion_from_brackets = _clean_for_speech(buffered_text)
        
        # --- èˆˆå¥®åº¦åƒæ•¸æ˜ å°„ (Speed/Pitch/Emotion) ---
        # ç²å–ç•¶å‰å¤§è…¦è³¦äºˆçš„ç©©å®šæ¨™ç±¤
        sovits_params = brain.sovits_tags.get(brain.arousal_level, brain.sovits_tags[ArousalLevel.NORMAL])
        
        # ğŸ­ åŠ¨æ€è¯­é€Ÿæ§åˆ¶ï¼šPEAK çŠ¶æ€æ—¶é™ä½è¯­é€Ÿï¼Œæ¨¡æ‹Ÿæ¬²è¨€åˆæ­¢ã€æ°”å–˜ååçš„æ„Ÿè§‰
        if brain.arousal_level == ArousalLevel.PEAK:
            # PEAK çŠ¶æ€ï¼šè¯­é€Ÿé™ä½åˆ° 0.9ï¼Œæ¨¡æ‹Ÿæ°”å–˜åå
            target_speed = 0.9
            logger.info(f"PEAK state detected: Speed reduced to 0.9 for breathless effect")
        else:
            # å…¶ä»–çŠ¶æ€ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            target_speed = sovits_params.get("speed", 1.0)
        
        target_pitch = sovits_params.get("pitch", 1.0)
        
        logger.info(f"Cartesia Multi-Param: Speed={target_speed}, Pitch={target_pitch}, Emotion={cartesia_emotion}")

        # ----------------------

        logger.info(f"AI Thinking Done. UI: {display_text} | Speech: {speech_text}")

        # ElevenLabs Integration
        from elevenlabs.client import ElevenLabs
        
        # éªŒè¯ API Key
        if not ELEVENLABS_API_KEY:
            raise HTTPException(status_code=500, detail="ELEVENLABS_API_KEY is missing. Please check environment variables.")
        
        logger.info(f"Initializing ElevenLabs client...")
        
        try:
            client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        except Exception as eleven_init_error:
            error_msg = str(eleven_init_error)
            logger.error(f"ElevenLabs client initialization failed: {error_msg}")
            raise HTTPException(status_code=500, detail=f"ElevenLabs åˆå§‹åŒ–å¤±è´¥: {error_msg}")
        
        # æ˜ å°„ ArousalLevel åˆ° ElevenLabs å‚æ•°
        eleven_params = {
            ArousalLevel.CALM: {"stability": 0.85, "similarity_boost": 0.8, "style": 0.0},
            ArousalLevel.NORMAL: {"stability": 0.7, "similarity_boost": 0.8, "style": 0.0},
            ArousalLevel.EXCITED: {"stability": 0.5, "similarity_boost": 0.7, "style": 0.25},
            ArousalLevel.INTENSE: {"stability": 0.4, "similarity_boost": 0.6, "style": 0.5},
            ArousalLevel.PEAK: {"stability": 0.3, "similarity_boost": 0.5, "style": 0.8}
        }
        
        current_config = eleven_params.get(brain.arousal_level, eleven_params[ArousalLevel.NORMAL])
        
        # å¦‚æœæ‹¬å·å†…æœ‰æ˜ç¡®æƒ…ç»ªï¼Œè¿›ä¸€æ­¥å¾®è°ƒ
        if emotion_from_brackets:
            current_config["stability"] = max(0.1, current_config["stability"] - 0.1)
            current_config["style"] = min(1.0, current_config["style"] + 0.15)
            logger.info(f"Adjusted ElevenLabs params due to emotional brackets: {current_config}")

        # æµå¼ä¼ è¾“ä¼˜åŒ–ï¼šç›´æ¥è¿”å›éŸ³è®¯æµ
        try:
            audio_stream = client.text_to_speech.convert(
                voice_id=VOICE_ID,
                optimize_streaming_latency="2",
                output_format="mp3_44100_128",
                text=speech_text,
                model_id=MODEL_ID,
                voice_settings=current_config
            )
        except Exception as tts_error:
            error_msg = str(tts_error)
            logger.error(f"ElevenLabs TTS API call failed: {error_msg}")
            if "401" in error_msg or "unauthorized" in error_msg.lower():
                raise HTTPException(
                    status_code=401,
                    detail=f"ElevenLabs API è®¤è¯å¤±è´¥ï¼ˆ401ï¼‰ï¼šAPI Key æ— æ•ˆæˆ–å·²è¿‡æœŸã€‚é”™è¯¯: {error_msg}"
                )
            elif "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                raise HTTPException(
                    status_code=429,
                    detail="ElevenLabs API è¯·æ±‚è¿‡äºé¢‘ç¹ï¼ˆ429ï¼‰ï¼šå·²è¾¾åˆ°é€Ÿç‡é™åˆ¶ã€‚è¯·ç¨åå†è¯•æˆ–æ£€æŸ¥é…é¢è®¾ç½®ã€‚"
                )
            else:
                raise HTTPException(status_code=500, detail=f"ElevenLabs TTS è°ƒç”¨å¤±è´¥: {error_msg}")
        
        import base64
        
        # æ”¶é›†éŸ³è¨Šæ•¸æ“šï¼ˆæµå¼è™•ç†ï¼‰
        try:
            audio_data = b"".join(audio_stream)
            audio_b64 = base64.b64encode(audio_data).decode('utf-8')
        except Exception as audio_error:
            logger.error(f"Audio data collection failed: {audio_error}")
            raise HTTPException(status_code=500, detail=f"éŸ³é¢‘æ•°æ®å¤„ç†å¤±è´¥: {audio_error}")

        return {
            "text": display_text,         # ç”¨äºæ˜¾ç¤ºåœ¨ UI ä¸Šçš„çº¯å‡€æ–‡å­—
            "raw_text": ai_response_text, # ä¿ç•™åŸå§‹æ–‡å­—ï¼ˆå¸¦æ ‡ç­¾ï¼‰ä»¥ä¾›è°ƒè¯•
            "audio": f"data:audio/mp3;base64,{audio_b64}",  # ä½¿ç”¨ MP3 æ ¼å¼
            "arousal": brain.arousal_level.name
        }

    except HTTPException:
        # é‡æ–°æŠ›å‡º HTTPExceptionï¼ˆåŒ…æ‹¬ 429ï¼‰
        raise
    except Exception as e:
        logger.error(f"Chat Pipeline Error: {str(e)}", exc_info=True)
        # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 ç›¸å…³é”™è¯¯
        error_str = str(e)
        if "429" in error_str or "è¯·æ±‚é¢‘ç‡è¿‡é«˜" in error_str or "è²è²ç´¯äº†" in error_str:
            raise HTTPException(
                status_code=429,
                detail="ä¸»äºº~è²è²ç´¯äº†ï¼Œè¯·ç­‰ 60 ç§’å†æ‰¾æˆ‘~ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰"
            )
        else:
            raise HTTPException(status_code=500, detail=str(e))

# é™æ€æ–‡ä»¶æŒ‚è½½ï¼ˆä½¿ç”¨ FastAPI StaticFilesï¼‰
_base_dir = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(_base_dir, "static")

# ç¡®ä¿ static ç›®å½•å­˜åœ¨å¹¶æŒ‚è½½
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory="static"), name="static")
    logger.info(f"Static files mounted at /static from directory: {static_dir}")
else:
    logger.warning(f"Static directory not found: {static_dir}")

@app.get("/favicon.ico")
async def favicon():
    """è¿”å› favicon æˆ– 204 No Content"""
    favicon_path = os.path.join(static_dir, "favicon.ico")
    if os.path.exists(favicon_path):
        return FileResponse(favicon_path)
    # å¦‚æœæ²¡æœ‰ faviconï¼Œè¿”å› 204 No Contentï¼ˆé¿å… 404 é”™è¯¯ï¼‰
    return Response(status_code=204)

@app.get("/")
async def root():
    return FileResponse(os.path.join(static_dir, "phi_chat.html"))

# ============================================
# å¤–äº¤å®˜æ¥å£ (MISSAV Bridge)
# ============================================
@app.post("/api/v1/chat")
async def missav_bridge(
    request: ChatRequest, 
    background_tasks: BackgroundTasks,
    api_key: str = Security(get_api_key)
):
    """
    å°ˆä¾›å¤–éƒ¨ç³»çµ±ï¼ˆå¦‚ MISSAVï¼‰èª¿ç”¨çš„ç²¾ç·»å°è£æ¥å£ã€‚
    åŒæ­¥è™•ç†èªéŸ³ç”Ÿæˆï¼Œä¸¦è‡ªå‹•å®‰æ’èƒŒæ™¯æ¸…ç†ä»»å‹™ã€‚
    """
    if not brain:
        raise HTTPException(status_code=500, detail="PhiBrain å¤§è…¦æœªå°±ç·’")

    try:
        from fastapi.concurrency import run_in_threadpool
        
        # 1. ç²å– LLM å›è¦† (ä½¿ç”¨ threadpool é¿å…é˜»å¡äº‹ä»¶è¿´åœˆ)
        ai_response_text, metadata = await run_in_threadpool(brain.generate_response, request.message)
        
        # 2. ç²å– UI é¡¯ç¤ºæ–‡å­—
        display_text = _clean_text(ai_response_text)
        
        # 3. èªéŸ³åŒ–æ¸…ç† (åµŒå¥—æ‹¬è™Ÿå·²åœ¨å…§éƒ¨å¾ªç’°è™•ç†)
        buffered_text = _clause_buffer(ai_response_text)
        speech_text, emotion_from_brackets = _clean_for_speech(buffered_text)
        
        # 4. å¾æ–‡æœ¬æå–æ¨™ç±¤
        cartesia_emotion = None
        emotion_match = re.search(r'<emotion\s+value=["\']([^"\']+)["\']\s*/>', ai_response_text)
        if emotion_match:
            cartesia_emotion = emotion_match.group(1)

        # 5. æ§‹å»ºåˆæˆåƒæ•¸ (ä½¿ç”¨ä¸»äººæŒ‡å®šçš„ 0.7/0.8 ç©©å®šåº¦)
        local_sovits_tags = {
            ArousalLevel.CALM: {"speed": 0.85, "pitch": 0.95},
            ArousalLevel.NORMAL: {"speed": 1.0, "pitch": 1.0},
            ArousalLevel.EXCITED: {"speed": 1.1, "pitch": 1.1},
            ArousalLevel.INTENSE: {"speed": 1.2, "pitch": 1.15},
            ArousalLevel.PEAK: {"speed": 1.3, "pitch": 1.2}
        }
        
        sovits_params = local_sovits_tags.get(brain.arousal_level, local_sovits_tags[ArousalLevel.NORMAL])
        target_speed = 0.9 if brain.arousal_level == ArousalLevel.PEAK else sovits_params.get("speed", 1.0)
        target_pitch = sovits_params.get("pitch", 1.0)
        
        base_emotion_config = {
            ArousalLevel.CALM: {"curiosity": "low", "stability": "high"},
            ArousalLevel.NORMAL: {"curiosity": "medium", "stability": "medium"},
            ArousalLevel.EXCITED: {"curiosity": "high", "stability": "medium"},
            ArousalLevel.INTENSE: {"curiosity": "high", "stability": "low"},
            ArousalLevel.PEAK: {"curiosity": "high", "stability": "low", "positivity": "high"}
        }
        
        emotion_config = base_emotion_config.get(brain.arousal_level, {}).copy()
        if emotion_from_brackets:
            emotion_config.update(emotion_from_brackets)
            
        generation_config = {
            "speed": target_speed,
            "pitch": target_pitch,
            "repetition_penalty": 1.15
        }
        if emotion_config:
            generation_config.update(emotion_config)
            

        # 5. æ§‹å»º ElevenLabs åƒæ•¸
        eleven_params = {
            ArousalLevel.CALM: {"stability": 0.85, "similarity_boost": 0.8, "style": 0.0},
            ArousalLevel.NORMAL: {"stability": 0.7, "similarity_boost": 0.8, "style": 0.0},
            ArousalLevel.EXCITED: {"stability": 0.5, "similarity_boost": 0.7, "style": 0.25},
            ArousalLevel.INTENSE: {"stability": 0.4, "similarity_boost": 0.6, "style": 0.5},
            ArousalLevel.PEAK: {"stability": 0.3, "similarity_boost": 0.5, "style": 0.8}
        }
        
        current_config = eleven_params.get(brain.arousal_level, eleven_params[ArousalLevel.NORMAL])
        
        # ç°¡å–®çš„æƒ…ç·’å¾®èª¿
        if emotion_from_brackets:
            current_config["stability"] = max(0.1, current_config["stability"] - 0.1)
            current_config["style"] = min(1.0, current_config["style"] + 0.15)
            
        # 6. ç”ŸæˆèªéŸ³ä¸¦å¯«å…¥æ–‡ä»¶ (ä½¿ç”¨ threadpool)
        def _generate_audio(text, settings):
            from elevenlabs.client import ElevenLabs
            if not ELEVENLABS_API_KEY:
                raise ValueError("ELEVENLABS_API_KEY is missing")
                
            client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
            
            # ä½¿ç”¨ convert ç”Ÿæˆå®Œæ•´éŸ³é »
            audio_generator = client.text_to_speech.convert(
                voice_id=VOICE_ID,
                output_format="mp3_44100_128",
                text=text,
                model_id=MODEL_ID,
                voice_settings=settings
            )
            return b"".join(audio_generator)

        audio_data = await run_in_threadpool(_generate_audio, speech_text, current_config)
        
        # ä½¿ç”¨ UUID å‘½åä¸¦å­˜å„²
        filename = f"phi_{uuid.uuid4().hex}.mp3"
        file_path = os.path.join(OUTPUT_DIR, filename)
        
        with open(file_path, "wb") as f:
            f.write(audio_data)
            
        # è¨»å†ŠèƒŒæ™¯æ¸…ç†ä»»å‹™ (600 ç§’å¾Œåˆªé™¤)
        background_tasks.add_task(cleanup_audio_file, file_path, 600)
        
        # æ§‹å»ºå¤–éƒ¨è¨ªå•é€£çµ
        # é€™è£¡å‡è¨­éƒ¨ç½²åœ¨ Railwayï¼Œæˆ‘å€‘éœ€è¦æ§‹å»ºçµ•å°è·¯å¾‘
        # å¦‚æœ request.base_url å­˜åœ¨å‰‡æ›´å¥½ï¼Œå¦å‰‡ä½¿ç”¨ç›¸å°æˆ–ç”±å‰ç«¯æ§‹å»º
        # ç‚ºäº†ç©©å®šï¼Œå›å‚³ç›¸å°è·¯å¾‘ç”±å‰ç«¯æˆ–å¤–éƒ¨çµ„è£
        audio_url = f"/static/output/{filename}"

        return {
            "reply": ai_response_text,    # å®Œæ•´çš„å¤§è…¦å›æ‡‰
            "text": display_text,         # æ·¨åŒ–å¾Œçš„ UI å±•ç¤ºæ–‡å­—
            "audio": audio_url,           # ç”Ÿæˆçš„èªéŸ³é€£çµ
            "phi_status": brain.arousal_level.name,
            "expires_in": 600             # æç¤ºå¤–éƒ¨ç³»çµ±è©²è³‡æºæœ‰æ•ˆæœŸ
        }

    except Exception as e:
        logger.error(f"Bridge API Error: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
